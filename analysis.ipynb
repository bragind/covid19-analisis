{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c448ca78",
   "metadata": {},
   "source": [
    "### 1. Подготовка среды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6c630c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Инициализация Spark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"COVID19_XRay_Analysis\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065a2970",
   "metadata": {},
   "source": [
    "### 2. Загрузка и предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b616be",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "df = spark.read.option(\"header\", \"true\") \\\n",
    "               .option(\"inferSchema\", \"true\") \\\n",
    "               .csv(\"metadata.csv\")\n",
    "\n",
    "# Просмотр структуры\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2661b4bd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Обработка пропусков и дубликатов\n",
    "df_clean = df.dropDuplicates()\n",
    "\n",
    "# Заполнение пропусков\n",
    "from pyspark.sql.functions import when, col, mean, mode\n",
    "\n",
    "# Возраст: заполняем медианой (приближённо — средним, так как PySpark не имеет median напрямую)\n",
    "mean_age = df_clean.select(mean(col(\"age\"))).collect()[0][0]\n",
    "df_clean = df_clean.fillna({\"age\": mean_age})\n",
    "\n",
    "# Пол: заполняем модой (наиболее частым значением)\n",
    "mode_sex = df_clean.groupBy(\"sex\").count().orderBy(desc(\"count\")).first()[\"sex\"]\n",
    "df_clean = df_clean.fillna({\"sex\": mode_sex})\n",
    "\n",
    "# Унификация диагнозов\n",
    "def unify_finding(finding):\n",
    "    if finding is None:\n",
    "        return \"Unknown\"\n",
    "    f = finding.lower()\n",
    "    if \"covid\" in f or \"sars-cov-2\" in f:\n",
    "        return \"COVID-19\"\n",
    "    elif \"pneumonia\" in f:\n",
    "        return \"Pneumonia\"\n",
    "    elif \"normal\" in f:\n",
    "        return \"Normal\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "unify_finding_udf = udf(unify_finding, StringType())\n",
    "df_clean = df_clean.withColumn(\"finding_unified\", unify_finding_udf(col(\"finding\")))\n",
    "\n",
    "# Фильтрация: оставляем только основные категории\n",
    "df_clean = df_clean.filter(col(\"finding_unified\").isin([\"COVID-19\", \"Pneumonia\", \"Normal\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c17c534",
   "metadata": {},
   "source": [
    "### 3. Анализ качества данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062077ab",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Распределение пропущенных значений\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "missing = df_clean.select([count(when(col(c).isNull() | isnan(c), c)).alias(c) for c in df_clean.columns])\n",
    "missing.show()\n",
    "\n",
    "# Аномалии: возраст < 0 или > 120\n",
    "df_clean = df_clean.filter((col(\"age\") >= 0) & (col(\"age\") <= 120))\n",
    "\n",
    "# Дата: фильтрация некорректных дат (опционально)\n",
    "# Здесь предполагаем, что дата в формате 'yyyy-MM-dd' или 'dd.MM.yyyy'\n",
    "# Для простоты — преобразуем и фильтруем\n",
    "df_clean = df_clean.withColumn(\"date_parsed\", to_date(col(\"date\"), \"yyyy-MM-dd\"))\n",
    "df_clean = df_clean.filter(col(\"date_parsed\").isNotNull())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b09cad",
   "metadata": {},
   "source": [
    "### SQL-аналитика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0650cace",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Регистрация таблицы для SQL\n",
    "df_clean.createOrReplaceTempView(\"xray_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9078ceb7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Базовая статистика по диагнозам\n",
    "q1 = spark.sql(\"\"\"\n",
    "    SELECT finding_unified AS diagnosis, COUNT(*) AS count\n",
    "    FROM xray_data\n",
    "    GROUP BY finding_unified\n",
    "    ORDER BY count DESC\n",
    "\"\"\")\n",
    "q1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc7f79d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Распределение по полу и диагнозам\n",
    "q2 = spark.sql(\"\"\"\n",
    "    SELECT sex, finding_unified AS diagnosis, COUNT(*) AS count\n",
    "    FROM xray_data\n",
    "    WHERE sex IN ('M', 'F')\n",
    "    GROUP BY sex, finding_unified\n",
    "    ORDER BY diagnosis, sex\n",
    "\"\"\")\n",
    "q2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748982f0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Топ-3 по возрасту в каждой группе диагнозов\n",
    "window_spec = Window.partitionBy(\"finding_unified\").orderBy(desc(\"age\"))\n",
    "q3 = df_clean.withColumn(\"age_rank\", row_number().over(window_spec)) \\\n",
    "             .filter(col(\"age_rank\") <= 3) \\\n",
    "             .select(\"finding_unified\", \"age\", \"patientid\", \"age_rank\")\n",
    "q3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b04957a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Временные тренды\n",
    "q4 = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        date_trunc('month', date_parsed) AS month,\n",
    "        finding_unified AS diagnosis,\n",
    "        COUNT(*) AS count\n",
    "    FROM xray_data\n",
    "    WHERE date_parsed IS NOT NULL\n",
    "    GROUP BY month, diagnosis\n",
    "    ORDER BY month, diagnosis\n",
    "\"\"\")\n",
    "q4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c0f2b2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Проекции и диагнозы\n",
    "q5 = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        view,\n",
    "        finding_unified AS diagnosis,\n",
    "        COUNT(*) AS count\n",
    "    FROM xray_data\n",
    "    WHERE view IS NOT NULL\n",
    "    GROUP BY view, finding_unified\n",
    "    ORDER BY view, count DESC\n",
    "\"\"\")\n",
    "q5.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98b05ee",
   "metadata": {},
   "source": [
    "### Обработка в PySpark с UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8677bce",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Категоризация возраста\n",
    "def categorize_age(age):\n",
    "    if age < 18:\n",
    "        return \"Child\"\n",
    "    elif age < 65:\n",
    "        return \"Adult\"\n",
    "    else:\n",
    "        return \"Elderly\"\n",
    "\n",
    "age_category_udf = udf(categorize_age, StringType())\n",
    "df_final = df_clean.withColumn(\"age_group\", age_category_udf(col(\"age\")))\n",
    "\n",
    "# Сохранение в Parquet (оптимизированный формат)\n",
    "df_final.write.mode(\"overwrite\").parquet(\"output/cleaned_data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877c64a4",
   "metadata": {},
   "source": [
    "### Визуализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5869df",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Конвертация в Pandas для визуализации (только для Notebook!)\n",
    "# Убедитесь, что данные помещаются в память!\n",
    "pdf = df_final.toPandas()\n",
    "\n",
    "# 1. Круговая диаграмма диагнозов\n",
    "plt.figure(figsize=(6, 6))\n",
    "pdf['finding_unified'].value_counts().plot.pie(autopct='%1.1f%%', startangle=90)\n",
    "plt.title(\"Распределение диагнозов\")\n",
    "plt.ylabel('')\n",
    "plt.show()\n",
    "\n",
    "# 2. Столбчатая диаграмма по возрастным группам\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=pdf, x='age_group', hue='finding_unified')\n",
    "plt.title(\"Распределение по возрастным группам и диагнозам\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "# 3. Временные тренды\n",
    "pdf_trend = q4.toPandas()\n",
    "pdf_trend['month'] = pd.to_datetime(pdf_trend['month'])\n",
    "plt.figure(figsize=(10, 5))\n",
    "for diagnosis in pdf_trend['diagnosis'].unique():\n",
    "    subset = pdf_trend[pdf_trend['diagnosis'] == diagnosis]\n",
    "    plt.plot(subset['month'], subset['count'], label=diagnosis, marker='o')\n",
    "plt.title(\"Временные тренды исследований\")\n",
    "plt.xlabel(\"Месяц\")\n",
    "plt.ylabel(\"Количество снимков\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 4. Heatmap: диагнозы vs проекции\n",
    "heatmap_data = pdf.groupby(['view', 'finding_unified']).size().unstack(fill_value=0)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(heatmap_data, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Heatmap: диагнозы vs проекции снимков\")\n",
    "plt.xlabel(\"Диагноз\")\n",
    "plt.ylabel(\"Проекция (view)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce07c54",
   "metadata": {},
   "source": [
    "Очистка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8720119b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
